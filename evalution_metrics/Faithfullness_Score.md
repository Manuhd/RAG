

## **Faithfulness means the answer is trusted *only because it is supported by your data (context) for the given query*.**

âœ”ï¸ **The LLM (or an evaluator LLM) gives this score**, not the user.

---

## Slight correction (important âš ï¸)

âŒ The **same LLM that generates the answer should NOT score itself**
âœ… A **separate evaluator step (LLM-as-a-judge)** gives the faithfulness score

This avoids bias.

---

## How it works in a RAG system (step-by-step)

### 1ï¸âƒ£ User asks a query

```
Query: What is the loan interest rate?
```

---

### 2ï¸âƒ£ Retriever fetches context (your data)

```
Context:
"Loan interest rate is 8% for salaried employees."
```

---

### 3ï¸âƒ£ Generator LLM produces answer

```
Answer:
"The loan interest rate is 8% and tenure is 20 years."
```

---

### 4ï¸âƒ£ Evaluator LLM computes faithfulness â­

It does **NOT use its own knowledge**
It checks **answer vs context only**

* Extract claims from answer
* Verify each claim against context
* Compute score

$$
\text{Faithfulness} =
\frac{\text{Supported claims}}
{\text{Total claims}}
$$

Result:

```
Faithfulness = 0.5
```
Letâ€™s calculate it **step by step**, very clearly ğŸ‘
This example is **perfect for understanding faithfulness**.

---

## Given

### **Context (your data)**

> â€œLoan interest rate is 8% for salaried employees.â€

### **Answer**

> â€œThe loan interest rate is 8% and tenure is 20 years.â€

---

## Step 1ï¸âƒ£ Break the answer into **claims**

A **claim = one factual statement**.

| Claim # | Claim text                   |
| ------- | ---------------------------- |
| 1       | Loan interest rate is **8%** |
| 2       | Loan tenure is **20 years**  |

â¡ï¸ **Total claims = 2**

---

## Step 2ï¸âƒ£ Check each claim against the **context**

| Claim               | Present in context? | Supported? |
| ------------------- | ------------------- | ---------- |
| Interest rate is 8% | Yes                 | âœ…          |
| Tenure is 20 years  | No                  | âŒ          |

â¡ï¸ **Supported claims = 1**

---

## Step 3ï¸âƒ£ Apply the faithfulness formula

$$
\text{Faithfulness} =
\frac{\text{Supported claims}}
{\text{Total claims}}
=====================

\frac{1}{2}
= 0.5
$$

---

## Final Result âœ…

```
Faithfulness score = 0.5 (50%)
```

---

## Why this matters

* The model **partially used your data**
* It **added extra information** (tenure) not present in context
* That extra part is a **hallucination**

---

## Key interview one-liner â­

> â€œFaithfulness is calculated by decomposing the answer into atomic claims and checking how many of those claims are supported by the retrieved context.â€

---

## Important note âš ï¸

Even if **tenure = 20 years is true in real life**,
â¡ï¸ it is **not faithful**, because **your data did not say it**.

---

## Visual summary

```
Claims:       [8% interest] [20-year tenure]
Context has:  [8% interest]
Score:        1 / 2 = 0.5
```

---

If you want next, I can:

* Show **Python code** that does this automatically
* Show **RAGAS internals**
* Explain **edge cases** (implicit claims, paraphrases)

Just say ğŸ‘

---

## Who gives the faithfulness score?

| Component       | Role                    |
| --------------- | ----------------------- |
| Generator LLM   | Produces answer         |
| Evaluator LLM   | Scores faithfulness     |
| RAGAS / TruLens | Orchestrates evaluation |

âœ”ï¸ The score is **automatic**

---

## Important distinction (interview favorite)

| Metric        | Meaning                        |
| ------------- | ------------------------------ |
| Faithfulness  | Answer is supported by context |
| Correctness   | Answer is factually correct    |
| Confidence    | How certain model sounds       |
| Hallucination | Unsupported claims             |

A response can be:

* **Correct but not faithful**
* **Faithful but incomplete**

---

## One-line â­

> â€œFaithfulness measures whether the LLMâ€™s answer is grounded in the retrieved data for the query, and the score is computed automatically using an LLM-based evaluation step.â€

---

## Production rule (best practice)

```text
If faithfulness < threshold â†’ regenerate or block answer
```

Typical threshold:

* 0.8â€“0.9 for enterprise apps

---

## Final confirmation âœ”ï¸

- âœ”ï¸ Faithfulness = trust from **your data**
- âœ”ï¸ Score is given by **LLM-based evaluator**
- âœ”ï¸ Used mainly for **RAG / document QA**

---

