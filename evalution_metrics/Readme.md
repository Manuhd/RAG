
# GenAI RAG Chatbot with Evaluation Metrics & Dashboard

This project demonstrates a **Retrieval-Augmented Generation (RAG)** chatbot built using **Python and Gemini LLM**, along with a **complete evaluation framework** to measure response quality, hallucination risk, and system reliability.

The system is designed to reflect **real-world enterprise GenAI practices**, especially for **banking / regulated domains**.



##  Features

- Retrieval-Augmented Question Answering (RAG)
- Grounded answer generation using Gemini LLM
- Automatic intent handling for ambiguous questions
- Strict hallucination control
- Per-response and system-level evaluation metrics
- Metrics logging to CSV
- Manager-friendly Streamlit dashboard



##  Architecture Overview

```

User Question
â†“
Retriever (Top-k from CSV using embeddings)
â†“
Context Construction
â†“
Gemini LLM (Grounded Prompt)
â†“
Answer
â†“
Evaluation Metrics
â†“
Metrics Logging (CSV)
â†“
Dashboard (Streamlit)

```

##  Project Structure


```
GEN AI Projects/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ loan_faq.csv
â”‚
â”œâ”€â”€ ingest.py                 # CSV ingestion & embedding creation
â”œâ”€â”€ retrieve.py               # Top-k retrieval logic
â”œâ”€â”€ ask_gemini.py             # Grounded answer generation
â”œâ”€â”€ evaluate.py               # Metrics calculation
â”œâ”€â”€ ground_truth.py           # true_id mapping from CSV
â”œâ”€â”€ metrics_logger.py         # Logs metrics to CSV
â”œâ”€â”€ plot_metrics.py           # Optional metric visualization
â”œâ”€â”€ main.py                   # Run chatbot + evaluation
â”œâ”€â”€ dashboard.py              # Streamlit dashboard
â”œâ”€â”€ metrics_log.csv           # Logged evaluation data
â””â”€â”€ README.md

```

---

## ğŸ“Š Evaluation Metrics

The system evaluates each response using the following metrics:

### ğŸ”¹ Retrieval Metric
- **Recall@k** â€“ Checks whether the correct answer (`true_id`) appears in the top-k retrieved results.

### ğŸ”¹ Answer Quality Metrics
- **Accuracy** â€“ Whether the generated answer matches the expected meaning.
- **Correctness** â€“ Direct comparison with ground-truth answer.
- **Faithfulness** â€“ Degree to which the answer is grounded in retrieved context (0â€“1).

### ğŸ”¹ Hallucination Metrics
- **Hallucination (Binary)** â€“ Whether the answer contains unsupported information.
- **Hallucination Risk (%)** â€“ Calculated as:

```

Hallucination Risk = (1 - Faithfulness) Ã— 100

```

### ğŸ”¹ Confidence Score
- Combined score derived from correctness, faithfulness, hallucination, and recall.

---

## ğŸ“ˆ Metrics Interpretation (Enterprise Standard)

| Metric | Target |
|------|-------|
| Faithfulness | â‰¥ 90% |
| Hallucination Risk | â‰¤ 5% |
| Hallucination Rate | â‰¤ 3â€“5% |
| Confidence Score | â‰¥ 85% |

---

##  Example Output

```

Enter your question: What documents are required for loan?

--- Per Question ---
Answer: ID proof, address proof, income proof.
Recall@3: 100%
Accuracy: 100%
Correctness: 100%
Faithfulness: 95%
Hallucination Risk: 5%
Confidence Score: 92%

````

---

##  Streamlit Dashboard

Run the dashboard using:

```bash
streamlit run dashboard.py
````

Dashboard displays:

* Average Confidence
* Faithfulness %
* Hallucination Rate %
* Hallucination Risk Distribution
* Logged Q&A history

---

##  Key Design Decisions

* **Extractive / Grounded Prompting** to prevent hallucinations
* **Strict refusal handling** for out-of-domain queries
* **Faithfulness-driven hallucination detection**
* **CSV-based logging** for auditability
* **Percentage-based metrics** for stakeholder readability

---

##  Real-World Relevance

This project mirrors how **enterprise GenAI systems** are built and evaluated in:

* Banking
* Finance
* Healthcare
* Regulated AI environments

It demonstrates **production thinking**, not just model usage.

---


## ğŸ› ï¸ Tech Stack

* Python
* Gemini LLM (Google Generative AI)
* Pandas, NumPy
* Streamlit
* CSV-based evaluation logging

---

## ğŸ“Œ Future Enhancements

* Batch evaluation on test sets
* Threshold-based auto-refusal
* Schema versioning for logs
* Alerting on hallucination spikes
* Confidence-based retry logic

---

## ğŸ‘¨â€ğŸ’» Author

Built as a **hands-on GenAI engineering project** focused on **real-world applicability and safety**.

---

