# ğŸ“˜ PROJECT: Gemini RAG Chatbot (FastAPI + Chroma + ChatGPT-Style UI)

This project is a full RAG (Retrieval-Augmented Generation) system using:

- âœ… Python (FastAPI backend)
- âœ… Gemini LLM (Google Generative AI)
- âœ… Chroma Vector Database
- âœ… PDF Upload & Embeddings
- âœ… ChatGPT-style UI (HTML + JS)
- âœ… Voice Input + File Upload


## ğŸ¯ What This Project Does

This AI chatbot can:

âœ… Read and process PDF resumes, policies, manuals, documents

âœ… Store and retrieve embeddings using Chroma DB

âœ… Answer questions based on the uploaded PDF (RAG)

âœ… Support voice input (speech-to-text)




### Demo
![alt text](https://github.com/Manuhd/RAG/blob/main/Gemini-RAG-Chatbot/RAG-project/RAG.PNG)

## ğŸ“ FILE STRUCTURE

```
rag-gemini/
â”‚â”€â”€ main.py                  # FastAPI backend (API routes)
â”‚â”€â”€ rag.py                   # PDF extract, chunking, retrieval logic
â”‚â”€â”€ embeddings.py            # Gemini embedding model
â”‚â”€â”€ requirements.txt         # Python dependencies
â”‚â”€â”€ .env                     # GEMINI_API_KEY
â”‚â”€â”€ data/                    # Uploaded PDF storage
â”‚â”€â”€ vectorstore/             # Chroma vector DB storage
â”‚â”€â”€ static/
â”‚     â””â”€â”€ index.html         # ChatGPT-style UI (frontend)
```
## ğŸ“Œ REQUIREMENTS
âœ… Software

Python 3.9+

pip

FastAPI

Uvicorn (server)

ChromaDB

Google Generative AI Python SDK

âœ… Python Libraries (requirements.txt)
```
fastapi
uvicorn
chromadb
PyPDF2
google-generativeai
python-dotenv
```
## ğŸ”§ INSTALLATION & SETUP
### 1ï¸âƒ£ Clone the Project
```
git clone https://github.com/your-username/rag-gemini.git
cd rag-gemini
```

### 2ï¸âƒ£ Install Dependencies
```
pip install -r requirements.txt
```

### 3ï¸âƒ£ Add Gemini API Key

Create .env
```
GEMINI_API_KEY=your_google_api_key
```
### 4ï¸âƒ£ Create Necessary Folders
```
mkdir data
mkdir vectorstore
mkdir static
```

Place the index.html UI file inside /static.

## ğŸ§  BACKEND COMPONENTS
1. embeddings.py

Handles Gemini embeddings.
```
import google.generativeai as genai
import os
from dotenv import load_dotenv

load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

def get_embedding(text: str):
    model = "models/text-embedding-004"
    result = genai.embed_content(model=model, content=text)
    return result['embedding']
```
âœ… 2. rag.py

Handles PDF processing, chunking, and Chroma DB retrieval.

âœ… Extract PDF
âœ… Chunk text
âœ… Store embeddings
âœ… Retrieve relevant chunks

âœ… 3. main.py

FastAPI server with:

âœ… /upload_pdf â†’ Upload + Process PDF
âœ… /ask â†’ Ask questions with RAG
âœ… Serves frontend /static/index.html

## ğŸŒ RUNNING THE PROJECT

Start FastAPI:
```
uvicorn main:app --reload
```

Open your browser:
```
http://127.0.0.1:8000/static/index.html
```
## ğŸ“Œ API ROUTES
### 1. Upload PDF
```
POST /upload_pdf
```
Body: multipart/form-data

Key	Value
file	PDF file

Response:
```
{
  "message": "PDF uploaded and processed."
}
```

2. Ask Question

GET /ask?q=Your question

Returns:

{
  "answer": "AI response based on the PDF context"
}

### ğŸ’¡ FEATURES INCLUDED

âœ… ChatGPT-style UI
âœ… Dark mode
âœ… Left sidebar chat history
âœ… Right-aligned user messages
âœ… Left-aligned bot messages
âœ… Animated typing dots
âœ… Live voice recording animation
âœ… Upload PDFs / Images / Docs
âœ… Extract PDF + Chunking + Embeddings
âœ… Chroma Vector DB storage
âœ… Gemini LLM answer generation
âœ… Kannada & English support
âœ… User-friendly interactions
